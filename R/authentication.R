##' Create a data frame of surveys that your log in can download
##'
##' @title DHS surveys that can be downloaded
##' @param your_email Character for email address for DHS website
##' @param your_password Character for password for DHS website
##' @param your_project Character string for the name of your project that gives you access to the DHS database
##' @param datasets_api_results Data.table for the api results for the datasets endpoint. Default = NULL and
##' generated by default if not declared.
##' @param surveys_api_results  Data.table for the api results for the surveys endpoint. Default = NULL and
##' generated by default if not declared.
##'
##' @note Credit for function to \url{https://github.com/ajdamico/lodown/blob/master/R/dhs.R}
##'
##' @return Returns \code{"data.frame"} of length 14:
##' \itemize{
##'       \item{"FileFormat"}
##'       \item{"FileSize"}
##'       \item{"DatasetType"}
##'       \item{"SurveyNum"}
##'       \item{"SurveyId"}
##'       \item{"FileType"}
##'       \item{"FileDateLastModified"}
##'       \item{"SurveyYearLabel"}
##'       \item{"SurveyType"}
##'       \item{"SurveyYear"}
##'       \item{"DHS_CountryCode"}
##'       \item{"FileName"}
##'       \item{"CountryName"}
##'       \item{"URLS"}
##'       }
##'
available_surveys <- function(your_email, your_password, your_project,
                              datasets_api_results = NULL,
                              surveys_api_results = NULL){


  # fetch all the surveys meta from the api if to already passed
  if(is.null(datasets_api_results) | is.null(surveys_api_results)){
    cli <- rdhs::dhs_client(root = file.path(tempdir(),as.numeric(Sys.time())))
    datasets_api_results <- cli$dhs_api_request("datasets",num_results = "all")
    surveys_api_results = cli$dhs_api_request("surveys",num_results = "ALL")
  }

  # set up temp file for unpacking bins
  tf <- tempfile(fileext = ".txt")
  values <- dhs_authenticate( your_email , your_password , your_project )

  # grab project number here
  project_number <- values$proj_id

  # re-access the download-datasets page
  z <- httr::POST( "https://dhsprogram.com/data/dataset_admin/download-datasets.cfm" , body = list( proj_id = project_number ) )

  # write the information from the `countries` page to a local file
  writeBin( z$content , tf )

  # load the text
  y <- readLines( tf , warn = FALSE )

  # Create post request for the download manager
  values <- list(Proj_ID = project_number,
                 action = "downloadmanager")

  # Head to download page
  z <- httr::POST( "https://dhsprogram.com/data/dataset_admin/index.cfm" , body = values)

  # Grab the content from that and start creation for last post request
  writeBin( z$content , tf )
  # load the text
  y <- readLines( tf , warn = FALSE )


  # Donqwload manager post creation
  ctrycodelist_lines <- grep("name=\"ctrycodelist\" value=",y,value = TRUE)
  ctrycodelist <- qdapRegex::rm_between(ctrycodelist_lines, '"', '"', extract=TRUE) %>% lapply(function(x) x[3])
  names(ctrycodelist) <- rep("ctrycodelist",length(ctrycodelist))

  filedatatypelist_DHS_lines <- grep("name=\"filedatatypelist_",y,value = TRUE)
  filedatatypelist_DHS <- qdapRegex::rm_between(filedatatypelist_DHS_lines, '"', '"', extract=TRUE) %>% lapply(function(x) x[3])
  names(filedatatypelist_DHS) <- paste0("filedatatypelist_",qdapRegex::rm_between(filedatatypelist_DHS_lines,"filedatatypelist_","\" value",extract=TRUE))

  fformatlist <- grep("fformatlist",y,value = TRUE)
  fformatlist <- qdapRegex::rm_between(fformatlist, '"', '"', extract=TRUE) %>% lapply(function(x) x[3])
  names(fformatlist) <- rep("fformatlist",length(fformatlist))

  values <- list(surveymode = "all",
                 Proj_ID = project_number,
                 action = "downloadmanager",
                 subaction = "Build URL File List",
                 sub = "submit",
                 submit = "Build URL File List",
                 FileDataTypeCode = "",
                 ctrycode = "")

  values <- append(values,values = c(ctrycodelist,filedatatypelist_DHS,fformatlist))

  # submit request for all the possible surveys
  message("Creating Download url list from DHS website...")
  z <- httr::POST( "https://dhsprogram.com/data/dataset_admin/index.cfm" , body = values)
  link.urls <- XML::xpathSApply( XML::htmlParse( httr::content( z ) ) , "//a" , XML::xmlGetAttr , "href" ) %>% unlist()

  # pull all links download and read in
  url_link <- paste0("https://dhsprogram.com",grep(pattern = "/data/download/urlslist",link.urls,value = TRUE))
  httr::GET(url_link , destfile = tf, httr::write_disk( tf , overwrite = TRUE ))
  urls <- readLines(tf)
  urls <- urls[-which(!nzchar(urls))]

  # start filling in the end result data frame of all available surveys
  res <- matrix(data = "",nrow = length(urls),ncol = dim(datasets_api_results)[2]+1)
  colnames(res) <- c(names(datasets_api_results),"URLS")
  res <- as.data.frame(res,stringsAsFactors = FALSE)
  res$URLS <- urls
  res$FileName <- qdapRegex::rm_between(urls,"Filename=","&Tp",extract = TRUE) %>% unlist

  # match meta using filenames
  fileName_matches <- match(toupper(res$FileName),toupper(datasets_api_results$FileName))
  res_matches <- which(!is.na(fileName_matches))
  if(sum(is.na(fileName_matches))>0) fileName_matches <- fileName_matches[-which(is.na(fileName_matches))]
  res[res_matches,1:length(datasets_api_results)] <- datasets_api_results[fileName_matches,]

  # if this is greater than 0, then their API is liekly out of date (which is an issue...)
  # TODO: Ask about how they would like to be contacated about this
  missings <- which(res$FileFormat=="")
  if(length(missings)>0){

    missing_country_codes <- unique(res$FileName[missings] %>% substr(start = 1, stop = 2))
    call <- surveys_api_results
    res$SurveyNum[missings] <- (qdapRegex::rm_between(res$URLS[missings],"surv_id=","&dm",extract = TRUE) %>% unlist)
    missing_survey_nums <- unique(res$SurveyNum[missings])

    ## TODO: MAKE THIS NOT TERRIBLE - will most likely break, and there is no telling that the surveys api is any better
    needed_cols <- c("SurveyId","SurveyYearLabel","SurveyType","SurveyYear","DHS_CountryCode","CountryName")

    # grab file types and format types for matching from the filenames
    file_types <- unique(res$FileType)
    file_types <- file_types[-which(file_types=="")]
    filetype_stems <- lapply(file_types,function(x) unique(toupper(substr(res$FileName[res$FileType==x],3,4)))) %>% unlist

    file_formats <- unique(res$FileFormat)
    file_formats <- file_formats[-which(file_formats=="")]
    fileformat_endings <- lapply(file_formats,function(x) unique(toupper(substr(res$FileName[res$FileFormat==x],7,8)))) %>% unlist

    # loop through all the missing survery numbers that we need to fill in for
    for(i in missing_survey_nums){

      # where are these missing surveys
      missing_pos <- missings[which(res$SurveyNum[missings]==i)]

      # is there any info about them from the surveys api
      if(length(which(call$SurveyNum==i))>0){
        res[missing_pos,needed_cols] <- call[which(call$SurveyNum==i),needed_cols]
      }

      # fill in file type and format from filename
      res$FileType[missing_pos] <- file_types[match(toupper(substr(res$FileName[missing_pos],3,4)),filetype_stems)]
      res$FileFormat[missing_pos] <- file_formats[match(toupper(substr(res$FileName[missing_pos],3,4)),fileformat_endings)]
    }

  }

  return(res)

}



##' Create a data frame of surveys that your log in can download
##'
##' @title Download surveys specified using output of \code{available_surveys}
##' @param your_email Character for email address for DHS website
##' @param your_password Character for password for DHS website
##' @param your_project Character string for the name of your project that gives you access to the DHS database
##' @param desired_survey Row from \code{available_surveys}
##' @param output_dir_root Directory where files are to be downloaded to
##' @param download_option Chracter dictating how the durvey is stored when downloaded. Must be one of:
##' \itemize{
##'       \item{"zip"} - Just the zip. "z" or anything like will match
##'       \item{"ex"} - Just the extracted zip. "e" or anything like will match
##'       \item{"rds"} - Just the read in and saved rds. "r" or anything like will match
##'       \item{"both"} - Both the rds and extract. "b" or anything like will match
##'}
##' @param reformat Boolean detailing whether dataset rds should be reformatted for ease of use later. Default = TRUE
##'
download_datasets <- function(   your_email , your_password , your_project ,
                                 desired_survey, output_dir_root=NULL,
                                 download_option = "both",
                                 reformat=TRUE){



  # possible download options:
  download_possibilities <- c("zip","ex","rds","both")

  # set up temp file for unpacking bins
  tf <- tempfile(fileext = ".txt")

  # handle output dir
  survey_dir <- paste(desired_survey$CountryName,desired_survey$SurveyYear,desired_survey$SurveyType,sep="_")
  survey_dir <- file.path(output_dir_root,survey_dir)

  # login
  values <- dhs_authenticate( your_email , your_password , your_project )
  project_number <- values$proj_id

  # access the download-datasets page
  z <- httr::POST( "https://dhsprogram.com/data/dataset_admin/download-datasets.cfm" , body = list( proj_id = project_number ) )

  # download our zip
  message("Downloading: \n", paste(desired_survey$CountryName,desired_survey$SurveyYear,
                                   desired_survey$SurveyType,desired_survey$FileType,
                                   desired_survey$FileFormat, collapse=", "))
  httr::GET(desired_survey$URLS[1], destfile = tf, httr::write_disk( tf , overwrite = TRUE ) , httr::progress() )

  # make sure the file-specific folder exists
  dir.create( survey_dir , showWarnings = FALSE, recursive = T )

  ## DOWNLOAD OPTIONS HANDLING:
  # 1. Just the zip
  if(grep(paste0(strsplit(download_option,"") %>% unlist,collapse="|"),download_possibilities)==1){

    res <- file.copy(tf,to = file.path(survey_dir,desired_survey$FileName))
    res <- if(res) file.path(survey_dir,desired_survey$FileName) else stop("Failed to donwload zip to where client root is - check write access?")

  }

  # 2. Just the extract
  if(grep(paste0(strsplit(download_option,"") %>% unlist,collapse="|"),download_possibilities)>=2){

    # unzip the download
    unzipped_files <- unzip_warn_fails(tf , exdir = survey_dir)

    # sometimes they have extra zips that are different surveys, e.g. Senegal 2014 GE
    still_zips <- grep(".zip|.ZIP",unzipped_files)
    if(length(still_zips)>0){
    zip_to_remove <- which(toupper(basename(unzipped_files[still_zips])) != toupper(desired_survey$FileName))
    file.remove(unzipped_files[zip_to_remove])
    unzipped_files <- unzipped_files[-zip_to_remove]
    }

    # some zipped files contained zipped subfiles
    for( this_zip in grep( "\\.zip$" , unzipped_files , ignore.case = TRUE , value = TRUE ) ){
      unzipped_files <- c( unzipped_files , unzip_warn_fails( this_zip , exdir = survey_dir ) )
    }

    res <- unzipped_files

    # 3. Just the rds
    if(grep(paste0(strsplit(download_option,"") %>% unlist,collapse="|"),download_possibilities)==3){

      # match to the actual dataset file rather than the others
      file_types <- c("dta","sav","dat","sas7bdat","dbf")
      file_endings <- strsplit(unzipped_files,".",fixed=T) %>% lapply(function(x) tail(x,1)) %>% unlist
      file <- unzipped_files[which(!is.na(match(toupper(file_endings),toupper(file_types))))]
      res <- dhs_read_dataset(file,reformat)

      if(!is.character(res)){
        rds_path <- file.path(survey_dir,paste0(strsplit(desired_survey$FileName,".",fixed=TRUE)[[1]][1],".rds"))
        saveRDS(res,rds_path)
        if(class(res)[1]=="SpatialPointsDataFrame"){
          res <- rds_path
        } else {
        res$Survey <- rds_path
        }
      }

      # remove unzipped files if not matching for "ex"
      # 4. Both extract and rds
      if(!grep(paste0(strsplit(download_option,"") %>% unlist,collapse="|"),download_possibilities)==4){
        file.remove(unzipped_files)
      }


    }




  }

  # delete the temporary file
  suppressWarnings( file.remove( tf ) )
  message( "survey donwload finished" )

  return(res)

}







##' Autheticate Users for DHS website
##'
##' @title DHS Wesbite Authentication
##' @param your_email Character for email address for DHS website
##' @param your_password Character for password for DHS website
##' @param your_project Character string for the name of your
##' project that gives you access to the DHS database
##'
##'
##' @note Credit for function to \url{https://github.com/ajdamico/lodown/blob/master/R/dhs.R}
##'
##' @return Returns list of length 3:
##' \itemize{
##'       \item{"user_name"}{ your email usually}
##'       \item{"user_pass"}{ your pasword you provided}
##'       \item{"proj_id"}{ your project number that will enable your project to be accessed downstream}
##'       }
##'
##'
##'

dhs_authenticate <- function( your_email , your_password , your_project ){


  # Argument Checking
  if(!is.character(your_email)) stop ("your_email is not a character string")
  if(!is.character(your_project)) stop ("your_password is not a character string")
  if(!is.character(your_password)) stop ("your_project is not a character string")

  # authentication page
  terms <- "https://dhsprogram.com/data/dataset_admin/login_main.cfm"

  # countries page
  downloads_page <- "https://dhsprogram.com/data/dataset_admin/download-datasets.cfm"

  # create a temporary file
  tf <- tempfile(fileext = ".txt")

  # set the username and password
  values <-
    list(
      UserName = your_email ,
      UserPass = your_password ,
      Submitted = 1 ,
      UserType = 2
    )

  # log in.
  message("Logging into DHS website...")
  #httr::GET( terms , query = values )
  z <- httr::POST( terms , body = values)

  # extract the available countries from the projects page
  #z <- httr::GET( downloads )

  # write the information from the `projects` page to a local file
  writeBin( z$content , tf )

  # load the text
  y <- readLines( tf , warn = FALSE )

  # figure out the project number - only use first 30 chars due to ellipsis formation
  project.line <- unique( y[ grepl( "option value" , y ) &
                               grepl( paste0(strsplit(your_project,"")[[1]][1:30],collapse="") , y , fixed = TRUE ) ] )

  # confirm only one project
  stopifnot( length( project.line ) == 1 )

  # extract the project number from the line above
  project_number <- gsub( "(.*)<option value=\"([0-9]*)\">(.*)" , "\\2" , project.line )

  # remove the tf
  suppressWarnings( file.remove( tf ) )

  # log in again, but specifically with the project number
  res <- list(
    user_name = your_email ,
    user_pass = your_password ,
    proj_id = project_number
  )



}
